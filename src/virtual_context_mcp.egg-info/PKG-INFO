Metadata-Version: 2.4
Name: virtual-context-mcp
Version: 0.1.0
Summary: Virtual infinite context MCP server for AI agents
Author: Virtual Context Team
License: MIT
Project-URL: Homepage, https://github.com/virtual-context/cont3xt
Project-URL: Bug Reports, https://github.com/virtual-context/cont3xt/issues
Project-URL: Source, https://github.com/virtual-context/cont3xt
Classifier: Development Status :: 3 - Alpha
Classifier: Intended Audience :: Developers
Classifier: License :: OSI Approved :: MIT License
Classifier: Programming Language :: Python :: 3
Classifier: Programming Language :: Python :: 3.11
Classifier: Programming Language :: Python :: 3.12
Requires-Python: >=3.11
Description-Content-Type: text/markdown
Requires-Dist: mcp>=1.0.0
Requires-Dist: tiktoken>=0.5.0
Requires-Dist: sentence-transformers>=2.2.0
Requires-Dist: qdrant-client>=1.7.0
Requires-Dist: neo4j>=5.15.0
Requires-Dist: numpy>=1.24.0
Requires-Dist: pydantic>=2.0.0
Requires-Dist: pyyaml>=6.0
Requires-Dist: spacy>=3.7.0

# CONT3XT - Virtual Infinite Context MCP Server

A sophisticated Virtual Infinite Context MCP (Model Context Protocol) Server designed for creative writing applications. CONT3XT provides seamless context management that allows AI conversations to maintain unlimited narrative memory while optimizing performance and hardware compatibility.

## üöÄ Features

### Core Capabilities
- **Virtual Infinite Context**: Maintains unlimited conversation history through intelligent memory management
- **Pressure Relief System**: Automatically manages context size using configurable thresholds (default: 12k tokens)
- **Multi-Tier Memory Storage**: SQLite archival, Qdrant vector search, and Neo4j knowledge graphs
- **Story-Aware Processing**: Specialized entity extraction for characters, locations, plot elements, and themes
- **Real-Time Memory Retrieval**: Multi-factor relevance scoring combining semantic similarity, entity overlap, temporal relevance, and graph connectivity

### MCP Integration
- **Story-Specific Tools**: Five specialized MCP tools for creative writing workflows
- **Resource Endpoints**: JSON API access to current context, characters, and memory statistics
- **Session Management**: Multi-session support with complete isolation
- **Type-Safe APIs**: Full Pydantic integration for robust operation

### Production Ready
- **Docker Deployment**: Complete containerization with health monitoring
- **CLI Interface**: Comprehensive command-line tools for development and production
- **Configuration Management**: YAML configuration with environment variable overrides
- **Testing Suite**: Complete integration tests with performance benchmarking

## üì¶ Installation

### Requirements
- Python 3.11+
- Docker and Docker Compose (for external services)
- 16GB+ RAM recommended for local LLM testing
- SSD storage for optimal database performance

### Quick Install
```bash
# Clone the repository
git clone <repository-url>
cd cont3xt

# Install the package
pip install -e .

# Verify installation
virtual-context-mcp --help
```

### Development Setup
```bash
# Install with development dependencies
pip install -e ".[dev]"

# Download required spaCy model
python -m spacy download en_core_web_sm

# Install pre-commit hooks (if using)
pre-commit install
```

## üê≥ Docker Deployment

### Production Deployment
```bash
# Start all services
docker-compose up -d

# Initialize databases
docker-compose exec virtual-context virtual-context-mcp --init-db

# View logs
docker-compose logs -f virtual-context
```

### Development with Docker
```bash
# Start external services only
docker-compose up -d qdrant neo4j

# Run the server locally
virtual-context-mcp --config configs/novel_writing.yaml
```

## üîß Configuration

### Basic Configuration
Create or modify `configs/novel_writing.yaml`:

```yaml
context:
  max_tokens: 12000
  pressure_threshold: 0.8
  relief_percentage: 0.4
  chunk_size: 3200
  token_model: "cl100k_base"

database:
  sqlite_path: "./data/memory.db"
  qdrant_url: "http://localhost:6333"
  qdrant_collection: "story_memory"
  neo4j_url: "bolt://localhost:7687"
  neo4j_user: "neo4j"
  neo4j_password: "password"

model_name: "all-MiniLM-L6-v2"
debug: false
```

### Environment Variables
Override any configuration value using environment variables:

```bash
export CONTEXT_MAX_TOKENS=16000
export DATABASE_QDRANT_URL="http://localhost:6333"
export DATABASE_NEO4J_PASSWORD="your-password"
export DEBUG=true
```

## üñ•Ô∏è CLI Usage

### Basic Commands
```bash
# Start the MCP server
virtual-context-mcp

# Use custom configuration
virtual-context-mcp --config path/to/config.yaml

# Initialize databases
virtual-context-mcp --init-db

# Development mode with debug logging
virtual-context-mcp --dev

# Custom host and port
virtual-context-mcp --host 0.0.0.0 --port 8080
```

### Available Options
```
--config, -c     Configuration file path
--host           Host to bind server (default: 127.0.0.1)
--port, -p       Port to bind server (default: 8000)
--log-level      Logging level (DEBUG, INFO, WARNING, ERROR)
--data-dir       Data storage directory (default: ./data)
--dev            Development mode with debug logging
--init-db        Initialize databases and exit
```

## üîå MCP Tools

CONT3XT provides five specialized MCP tools for creative writing:

### `continue_story`
Process user-assistant interactions with automatic context management.
```json
{
  "name": "continue_story",
  "arguments": {
    "user_input": "The detective examined the mysterious letter...",
    "session_id": "novel_chapter_1"
  }
}
```

### `search_story_memory`
Semantic search through story memories with optional entity filtering.
```json
{
  "name": "search_story_memory",
  "arguments": {
    "query": "What did Sarah say about the mansion?",
    "session_id": "novel_chapter_1",
    "entity_filter": ["Sarah", "mansion"]
  }
}
```

### `get_character_info`
Retrieve character details and relationships.
```json
{
  "name": "get_character_info",
  "arguments": {
    "character_name": "Detective Morgan",
    "session_id": "novel_chapter_1"
  }
}
```

### `get_plot_threads`
Track active plot lines and their resolution status.
```json
{
  "name": "get_plot_threads",
  "arguments": {
    "session_id": "novel_chapter_1",
    "include_resolved": false
  }
}
```

### `get_context_stats`
Real-time context pressure and memory statistics.
```json
{
  "name": "get_context_stats",
  "arguments": {
    "session_id": "novel_chapter_1"
  }
}
```

## üìä MCP Resources

Access data through resource endpoints:

- `story://current-context` - Active context window information
- `story://characters` - All characters in current session  
- `story://memory-stats` - Comprehensive memory usage statistics

## üß™ Testing

### Run Tests
```bash
# Run all tests
python run_tests.py

# Run with coverage
python run_tests.py --coverage

# Run specific test suite
pytest tests/integration/test_full_story_workflow.py -v

# Performance benchmarking
pytest tests/integration/test_full_story_workflow.py::test_performance_benchmarks -v
```

### Integration Testing
The test suite includes:
- Full story workflow testing with realistic scenarios
- Performance benchmarking with configurable targets
- Memory validation and pressure relief testing
- Character consistency across relief cycles
- Error recovery and resilience testing

## üèóÔ∏è Architecture

### Core Components

#### Context Manager (`context_manager.py`)
- Orchestrates conversation flow and pressure monitoring
- Manages context assembly from memory and current input
- Triggers pressure relief at configurable thresholds

#### Pressure Relief Valve (`pressure_valve.py`)
- Handles context overflow through intelligent chunk extraction
- Maintains optimal attention patterns by keeping context under limits
- Preserves narrative coherence during relief operations

#### Memory Storage Tiers
- **SQLite**: Conversation archival and session management
- **Qdrant**: Vector similarity search for semantic retrieval
- **Neo4j**: Knowledge graph for entity relationships

#### Story-Aware Processing
- **Entity Extraction**: Characters, locations, plot elements, themes
- **Chunking**: Preserves narrative boundaries and dialogue integrity
- **Relevance Scoring**: Multi-modal scoring for memory retrieval

### Memory Retrieval Algorithm
The system uses a sophisticated multi-factor scoring system:
- **40% Semantic Similarity**: Vector embedding cosine similarity
- **30% Entity Overlap**: Jaccard similarity of entity sets
- **20% Temporal Relevance**: Exponential decay (24-hour half-life)
- **10% Graph Connectivity**: Neo4j relationship strength

## üîÑ How It Works

1. **Input Processing**: User input is tokenized and analyzed for entities
2. **Context Assembly**: Recent context (70%) + relevant memories (30%)
3. **Pressure Monitoring**: Continuous token count tracking
4. **Pressure Relief**: When threshold exceeded, remove 40% of context as semantic chunks
5. **Memory Storage**: Extracted chunks stored across all storage tiers
6. **Background Processing**: Entity extraction and relationship building happen asynchronously

## üìà Performance

### Benchmarks
- **Context Assembly**: <100ms for 12k token windows
- **Memory Retrieval**: <200ms for semantic search with 1000+ memories
- **Entity Extraction**: <150ms for 3.2k token chunks
- **Pressure Relief**: <300ms for full relief cycle

### Scalability
- Handles 100+ conversation turns without performance degradation
- Memory storage scales horizontally with external services
- Configurable limits support different hardware configurations

## üõ†Ô∏è Development

### Project Structure
```
cont3xt/
‚îú‚îÄ‚îÄ src/virtual_context_mcp/     # Main package
‚îÇ   ‚îú‚îÄ‚îÄ context_manager.py       # Core orchestration
‚îÇ   ‚îú‚îÄ‚îÄ pressure_valve.py        # Context relief logic
‚îÇ   ‚îú‚îÄ‚îÄ server.py                # MCP server implementation
‚îÇ   ‚îú‚îÄ‚îÄ config/                  # Configuration management
‚îÇ   ‚îú‚îÄ‚îÄ chunking/                # Tokenization and chunking
‚îÇ   ‚îú‚îÄ‚îÄ memory/                  # Storage implementations
‚îÇ   ‚îú‚îÄ‚îÄ entities/                # Entity extraction
‚îÇ   ‚îî‚îÄ‚îÄ retrieval/               # Memory retrieval
‚îú‚îÄ‚îÄ tests/                       # Test suite
‚îú‚îÄ‚îÄ configs/                     # Configuration files
‚îú‚îÄ‚îÄ docker/                      # Docker deployment
‚îî‚îÄ‚îÄ data/                        # Data storage
```

### Contributing
1. Fork the repository
2. Create a feature branch
3. Add tests for new functionality
4. Ensure all tests pass
5. Submit a pull request

### Code Style
- Follow PEP 8 guidelines
- Use type hints throughout
- Add docstrings for all public methods
- Maintain test coverage above 90%

## üìù License

MIT License - see LICENSE file for details.

## ü§ù Support

- **Issues**: Report bugs and feature requests via GitHub Issues
- **Documentation**: See `CLAUDE.md` for detailed implementation notes
- **Development**: Check `implementation/` directory for task-specific documentation

## üéØ Roadmap

- [ ] Web UI for memory exploration and management
- [ ] Additional embedding model support (OpenAI, Cohere, etc.)
- [ ] Advanced entity relationship inference
- [ ] Multi-language support for international stories
- [ ] Cloud deployment templates (AWS, GCP, Azure)
- [ ] Integration with popular writing tools

---

**CONT3XT** - Bringing infinite context to AI-powered creative writing. üöÄ‚úçÔ∏è
